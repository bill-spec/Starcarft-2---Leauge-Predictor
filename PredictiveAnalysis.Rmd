---
title: "Random Forest"
author: "Bill Lang"
date: "7/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(randomForest)
library(ggthemes)
```

```{r}
load(file = "cleanedLeague.RData")
leagueData
```

```{r}
set.seed(343)
div1 <- c(0,333,665,998,1330,1662,1994,2326,2658,2990)
div2 <- c(332,664,997,1329,1661,1993,2325,2657,2989,3328)
div1;div2
shuf <- sample(nrow(leagueData))
leagueShuffed <- leagueData[shuf,]
leagueShuffed

```

```{r}
error <- c(1:10)
error

for(j in 1:10){
  
  testing <- leagueShuffed[c(div1[j]:div2[j]),]
  training <- leagueShuffed[-c(div1[j]:div2[j]),]
  

    mod <- lm(LeagueIndex~., data = training)
    yhat <- predict(mod, newdata = testing)
    MSE <- mean( (yhat - testing$LeagueIndex)^2 )
    error[j] <- MSE

}

error
which(error == min(error), arr.ind = TRUE);min(error)
hist(error)
```



Random Forest Regression 

Manual cross-validation for both the error rate and the mtry parameter. The default for the mtry of this packages is $\sqrt p$ which would be $4.5$, however, cross validation found anything between $3$ and $9$ provided the best, identical results. 

```{r}
set.seed(343)
div1 <- c(0,333,665,998,1330,1662,1994,2326,2658,2990)
div2 <- c(332,664,997,1329,1661,1993,2325,2657,2989,3328)
div1;div2
shuf <- sample(nrow(leagueData))
leagueShuffed <- leagueData[shuf,]
leagueShuffed

```

```{r}
errors <- matrix(nrow = 10, ncol = 19)
for(j in 1:10){
  
  testing <- leagueShuffed[c(div1[j]:div2[j]),]
  training <- leagueShuffed[-c(div1[j]:div2[j]),]
  
  for(i in 1:19){
    mod <- randomForest(LeagueIndex~., mtry = i, ntrees = 1000, data = training)
    yhat <- predict(mod, newdata = testing)
    MSE <- mean( (yhat - testing$LeagueIndex)^2 )
    errors[j,i] <- MSE
  }
}

which(errors == min(errors), arr.ind = TRUE);min(errors)
hist(colMeans(errors), breaks = 30)
errors <- as.data.frame(errors)
errors <- errors %>% pivot_longer(V1:V19, names_to = "mtry", values_to = "ErrorRate")
errors

ggplot(errors, mapping = aes(ErrorRate), bins = 10) + 
  geom_histogram()+
  xlab("Error Rate")+
  ylab("Frequency")+
  theme_light()
```

Most of the mtry parameters performed similiarly to one another after 3. We can conclude that the random forest default of $\sqrt p$ would likely perform well. 

```{r}
errorData <- as.data.frame(errors)
errorData <- errorData %>% pivot_longer(V1:V19, names_to = "mtry", values_to = "ErrorRate")
errorData <- as.data.frame(lapply(errorData, function(y) gsub("V", "", y)))
errorData <- errorData %>% mutate_all(as.double)

errorData %>% ggplot() + 
  geom_boxplot(aes(x = factor(mtry), ErrorRate))+
  xlab("mtry Parameter")+
  ylab("Recorded Error Rate")+
  theme_light()
```
 









Boosted Trees

Boosted forests 

```{r}
library(gbm)
```


```{r}
boost.league <- gbm(LeagueIndex~., data = training, distribution = "gaussian", n.trees = 5000, interaction.depth = 2, shrinkage = 0.1, verbose = F)
yhat <- predict(boost.league, newdata = testing)
MSE <- mean( (yhat - testing$LeagueIndex)^2 )
MSE
```

```{r}
seq(from=  0.01, to = 0.1, by = 0.01)

```

```{r}
L3 <- LETTERS[1:3]
fac <- sample(L3, 10, replace = TRUE)
fac
(d <- data.frame(x = 0, y = 0, 1:10))
d
```

```{r}

errors <- matrix(nrow = 19, ncol = 10)
learningRate <- seq(from=  0.01, to = 0.1, by = 0.01)
errors[1,2]
errors
for(i in 1:19){
  for(j in 1:10){
boost.league <- gbm(LeagueIndex~., data = training, distribution = "gaussian", n.trees = 5000, interaction.depth = i, shrinkage = learningRate[j], verbose = F)
yhat <- predict(boost.league, newdata = testing)
MSE <- mean( (yhat - testing$LeagueIndex)^2 )
errors[i,j] <- MSE
  }
}

errors
which.min(errors);min(errors)
hist(errors)

```














Classification Forest

```{r}
set.seed(343)
data2 <- data 
data2$LeagueIndex <- as.factor(data2$LeagueIndex)
train <- sample(nrow(data2)*.8)
training <- data2[train,]
testing <- data2[-train,]
```

```{r}
errors <- c(1:19)
for(i in 1:19){
mod <- randomForest(LeagueIndex~., mtry = i, ntrees = 1000, data = training)
yhat <- predict(mod, newdata = testing)
MSE <- mean( (yhat != testing$LeagueIndex) )
errors[i] <- MSE
}
errors
which.min(errors);min(errors)
```


